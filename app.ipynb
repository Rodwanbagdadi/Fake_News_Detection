{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39c74043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, redirect\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5acb7708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat an app object using the flask class\n",
    "app = Flask(__name__)\n",
    "app.config['UPLOAD_FOLDER'] = 'uploads/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3de43e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\OMEN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\OMEN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "portStemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dee8d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models and vectorizer once\n",
    "xgboost_model = joblib.load(\"models/xgboost_model.pkl\")\n",
    "random_forest_model = joblib.load(\"models/random_forest_model.pkl\")\n",
    "lightgbm_model = joblib.load(\"models/light_gbm_model.pkl\")\n",
    "logistic_regression_model = joblib.load(\"models/logistic_regression_model.pkl\")\n",
    "vectorizer = joblib.load(\"models/vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "973e3206",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"XGBoost\": xgboost_model,\n",
    "    \"Random Forest\": random_forest_model,\n",
    "    \"LightGBM\": lightgbm_model,\n",
    "    \"Logistic Regression\": logistic_regression_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1f05616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess(text):\n",
    "    text = clean(text)\n",
    "    tokens = [portStemmer.stem(word) for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66bc731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ce8de34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [28/Apr/2025 21:32:57] \"GET / HTTP/1.1\" 200 -\n",
      "c:\\Users\\OMEN\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [28/Apr/2025 21:33:10] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# In your predict() function inside app.py\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    article = request.form['article']\n",
    "\n",
    "    results, consensus = predict_single_article(article, return_detailed=True)\n",
    "\n",
    "    # Add description for each model\n",
    "    descriptions = {\n",
    "        \"XGBoost\": \"An optimized gradient boosting library designed for high performance.\",\n",
    "        \"Random Forest\": \"An ensemble of decision trees trained on random subsets of data.\",\n",
    "        \"LightGBM\": \"A fast, gradient-boosting framework using tree-based learning algorithms.\",\n",
    "        \"Logistic Regression\": \"A simple linear model for binary classification problems.\"\n",
    "    }\n",
    "\n",
    "    return render_template('index.html', results=results, consensus=consensus, descriptions=descriptions)\n",
    "\n",
    "def predict_single_article(article, return_detailed=False):\n",
    "    article_vectorized = vectorizer.transform([article])\n",
    "\n",
    "    model_results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        prob = model.predict_proba(article_vectorized)[0]\n",
    "        prediction = model.predict(article_vectorized)[0]\n",
    "        confidence = max(prob) * 100\n",
    "        label = \"FAKE\" if prediction == 1 else \"REAL\"\n",
    "        model_results[name] = {\n",
    "            \"label\": label,\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "\n",
    "    # Sort by confidence descending\n",
    "    model_results = dict(sorted(model_results.items(), key=lambda item: item[1]['confidence'], reverse=True))\n",
    "\n",
    "    # Calculate consensus\n",
    "    votes = [info['label'] for info in model_results.values()]\n",
    "    consensus_label = \"FAKE\" if votes.count(\"FAKE\") >= 3 else \"REAL\"\n",
    "\n",
    "    if return_detailed:\n",
    "        return model_results, consensus_label\n",
    "    else:\n",
    "        return {\n",
    "            \"article\": article,\n",
    "            \"results\": model_results,\n",
    "            \"consensus\": consensus_label\n",
    "        }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(app.config['UPLOAD_FOLDER']):\n",
    "        os.makedirs(app.config['UPLOAD_FOLDER'])\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26062ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [27/Apr/2025 12:06:45] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Apr/2025 12:06:49] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Apr/2025 12:06:55] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# #Define the route to be home \n",
    "# #The decorator below links the relative route of the URL to the function it is dec\n",
    "# #Here, home function is with '/', our root directory.\n",
    "# # Running the app sends us to index.html.\n",
    "# # Note that the render_template means it looks for the file in the templates folder. \n",
    "# #use the route() decorator to tell Flask what URL should trigger our function.\n",
    "# @app.route('/predict', methods=['POST'])\n",
    "# def predict():\n",
    "#     if model is None or vectorizer is None:\n",
    "#         return render_template('index.html', prediction_text='Model not loaded correctly.')\n",
    "\n",
    "#     try:\n",
    "#         article_text = request.form['article']\n",
    "#         processed_text = preprocess(article_text)\n",
    "#         features = vectorizer.transform([processed_text])\n",
    "#         prediction = model.predict(features)\n",
    "\n",
    "#         output = \"REAL\" if prediction[0] == 1 else \"FAKE\"\n",
    "#         return render_template('index.html', prediction_text=f'This news is {output}')\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error during prediction: {e}\")\n",
    "#         return render_template('index.html', prediction_text='Error during prediction.')\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     app.run(debug=True, use_reloader=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
